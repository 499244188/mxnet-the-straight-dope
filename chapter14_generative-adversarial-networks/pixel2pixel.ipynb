{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel to Pixel Generative Adversarial Networks\n",
    "\n",
    "[Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434) is a model which is capable of learning resuable feature representations from large unlabeled image datasets. It helps bridge the gap between the success of CNNs for supervised learning and unsupervised learning. \n",
    "\n",
    "In this tutorial, we'll use DCGAN model to train on [LWF Face Dataset](http://vis-www.cs.umass.edu/lfw/), which contains about 13000 images of faces. We'll see that good image representation can be built by GAN and our model is capable of generating photo-realistic human face images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import tarfile\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet.gluon import nn, utils\n",
    "from mxnet.gluon.nn import Dense, Activation, Conv2D, Conv2DTranspose, \\\n",
    "    BatchNorm, LeakyReLU, Flatten, HybridSequential, HybridBlock, Dropout\n",
    "from mxnet import autograd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "latent_z_size = 100\n",
    "\n",
    "use_gpu = True\n",
    "ctx = mx.gpu() if use_gpu else mx.cpu()\n",
    "\n",
    "lr = 0.0002\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and preprocess LWF Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'facades'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first resize images to size 64*64. Then normalize image pixel values to be between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_wd = 256\n",
    "img_ht = 256\n",
    "train_img_path = '%s/train' % (dataset)\n",
    "val_img_path = '%s/val' % (dataset)\n",
    "\n",
    "def load_data(path, batch_size, is_reversed=False):\n",
    "    img_in_list = []\n",
    "    img_out_list = []\n",
    "    for path, _, fnames in os.walk(path):\n",
    "        for fname in fnames:\n",
    "            if not fname.endswith('.jpg'):\n",
    "                continue\n",
    "            img = os.path.join(path, fname)\n",
    "            img_arr = mx.image.imread(img)\n",
    "            # Crop input and output images\n",
    "            img_arr_in, img_arr_out = [mx.image.fixed_crop(img_arr, 0, 0, img_wd, img_ht),\n",
    "                                       mx.image.fixed_crop(img_arr, img_wd, 0, img_wd, img_ht)]\n",
    "            img_arr_in, img_arr_out = [nd.transpose(img_arr_in, (2,0,1)), \n",
    "                                       nd.transpose(img_arr_out, (2,0,1))]\n",
    "            img_arr_in, img_arr_out = [img_arr_in.reshape((1,) + img_arr_in.shape), \n",
    "                                       img_arr_out.reshape((1,) + img_arr_out.shape)]\n",
    "            img_in_list.append(img_arr_out if is_reversed else img_arr_in)\n",
    "            img_out_list.append(img_arr_in if is_reversed else img_arr_out)\n",
    "\n",
    "    return mx.io.NDArrayIter(data=[nd.concatenate(img_in_list), \n",
    "                                   nd.concatenate(img_out_list)], batch_size=batch_size)\n",
    "\n",
    "train_data = load_data(train_img_path, batch_size)\n",
    "val_data = load_data(val_img_path, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize 4 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img_arr):\n",
    "    plt.imshow(img_arr.asnumpy().transpose(1, 2, 0).astype(np.uint8))\n",
    "    plt.axis('off')\n",
    "\n",
    "img_in_list, img_out_list = train_data.next().data\n",
    "for i in range(4):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    visualize(img_in_list[i])\n",
    "    plt.subplot(2,4,i+5)\n",
    "    visualize(img_out_list[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the networks\n",
    "\n",
    "The core to DCGAN architecture is adopting and modifying CNN architecture:\n",
    "* Replace any pooling layers with strided convolutions (discriminator) and fractional-strided convolutions (generator).\n",
    "\n",
    "* Use batchnorm in both the generator and the discriminator.\n",
    "\n",
    "* Remove fully connected hidden layers for deeper architectures.\n",
    "\n",
    "* Use ReLU activation in generator for all layers except for the output, which uses Tanh.\n",
    "\n",
    "* Use LeakyReLU activation in the discriminator for all layers.\n",
    "\n",
    "![alt text](img/dcgan.png \"DCGAN Architecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Unet generator skip block\n",
    "class UnetSkipUnit(HybridBlock):\n",
    "    def __init__(self, inner_channels, outer_channels, inner_block=None, innermost=False, outermost=False,\n",
    "                 use_dropout=False, use_bias=False):\n",
    "        super(UnetSkipUnit, self).__init__()\n",
    "        self.outermost = outermost\n",
    "        en_conv = Conv2D(channels=inner_channels, kernel_size=4, strides=2, padding=1,\n",
    "                         in_channels=outer_channels, use_bias=use_bias)\n",
    "        en_relu = LeakyReLU(alpha=0.2)\n",
    "        en_norm = BatchNorm(in_channels=inner_channels)\n",
    "        de_relu = Activation(activation='relu')\n",
    "        de_norm = BatchNorm(in_channels=outer_channels)\n",
    "\n",
    "        if innermost:\n",
    "            de_conv = Conv2DTranspose(channels=outer_channels, kernel_size=4, strides=2, padding=1,\n",
    "                                      in_channels=inner_channels, use_bias=use_bias)\n",
    "            encoder = [en_relu, en_conv]\n",
    "            decoder = [de_relu, de_conv, de_norm]\n",
    "            model = encoder + decoder\n",
    "        elif outermost:\n",
    "            de_conv = Conv2DTranspose(channels=outer_channels, kernel_size=4, strides=2, padding=1,\n",
    "                                      in_channels=inner_channels * 2)\n",
    "            encoder = [en_conv]\n",
    "            decoder = [de_relu, de_conv, Activation(activation='tanh')]\n",
    "            model = encoder + [inner_block] + decoder\n",
    "        else:\n",
    "            de_conv = Conv2DTranspose(channels=outer_channels, kernel_size=4, strides=2, padding=1,\n",
    "                                      in_channels=inner_channels * 2, use_bias=use_bias)\n",
    "            encoder = [en_relu, en_conv, en_norm]\n",
    "            decoder = [de_relu, de_conv, de_norm]\n",
    "            model = encoder + [inner_block] + decoder\n",
    "            if use_dropout:\n",
    "                model += [Dropout(rate=0.5)]\n",
    "\n",
    "        self.model = HybridSequential()\n",
    "        for block in model:\n",
    "            self.model.add(block)\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        if self.outermost:\n",
    "            return self.model(x)\n",
    "        else:\n",
    "            return F.concat([self.model(x), x], dim=1)\n",
    "\n",
    "# Define Unet generator\n",
    "class UnetGenerator(HybridBlock):\n",
    "    def __init__(self, in_channels, num_downs, ngf=64, use_dropout=False):\n",
    "        super(UnetGenerator, self).__init__()\n",
    "\n",
    "        #Build unet generator structure\n",
    "        unet = UnetSkipUnit(ngf * 8, ngf * 8, innermost=True)\n",
    "        for _ in range(num_downs - 5):\n",
    "            unet = UnetSkipUnit(ngf * 8, ngf * 8, unet, use_dropout=True)\n",
    "        unet = UnetSkipUnit(ngf * 8, ngf * 4, unet)\n",
    "        unet = UnetSkipUnit(ngf * 4, ngf * 2, unet)\n",
    "        unet = UnetSkipUnit(ngf * 2, ngf * 1, unet)\n",
    "        unet = UnetSkipUnit(ngf, in_channels, unet, outermost=True)\n",
    "\n",
    "        self.model = unet\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Define the PatchGAN discriminator\n",
    "class Disciminator(HybridBlock):\n",
    "    def __init__(self, in_channels, ndf=64, n_layers=3, use_sigmoid=True, use_bias=True):\n",
    "        super(Disciminator, self).__init__()\n",
    "        self.model = HybridSequential()\n",
    "        kernel_size = 4\n",
    "        padding = int(mx.nd.ceil((kernel_size - 1)/2))\n",
    "        self.model.add(Conv2D(channels=ndf, kernel_size=kernel_size, strides=2,\n",
    "                              padding=padding, in_channels=in_channels))\n",
    "        self.model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        nf_mult = 1\n",
    "        for n in range(1, n_layers):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            self.model.add(Conv2D(channels=ndf * nf_mult, kernel_size=kernel_size, strides=2,\n",
    "                                  padding=padding, in_channels=ndf * nf_mult_prev,\n",
    "                                  use_bias=use_bias))\n",
    "            self.model.add(BatchNorm(in_channels=ndf * nf_mult))\n",
    "            self.model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        self.model.add(Conv2D(channels=ndf * nf_mult, kernel_size=kernel_size, strides=1,\n",
    "                              padding=padding, in_channels=ndf * nf_mult_prev,\n",
    "                              use_bias=use_bias))\n",
    "        self.model.add(BatchNorm(in_channels=ndf * nf_mult))\n",
    "        self.model.add(LeakyReLU(alpha=0.2))\n",
    "        self.model.add(Conv2D(channels=1, kernel_size=kernel_size, strides=1,\n",
    "                              padding=padding, in_channels=ndf * nf_mult))\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "netG = UnetGenerator(in_channels=3, num_downs=8)\n",
    "netD = Discriminator(in_channels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Loss Function and Optimizer\n",
    "We use binary cross entropy as loss function and adam as optimizer. Initialize parameters with normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "GAN_loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "L1_loss = gluon.loss.L1Loss()\n",
    "\n",
    "# initialize the generator and the discriminator\n",
    "netG.initialize(mx.init.Normal(0.02), ctx=ctx)\n",
    "netD.initialize(mx.init.Normal(0.02), ctx=ctx)\n",
    "\n",
    "# trainer for the generator and the discriminator\n",
    "trainerG = gluon.Trainer(netG.collect_params(), 'adam', {'learning_rate': lr, 'beta1': beta1})\n",
    "trainerD = gluon.Trainer(netD.collect_params(), 'adam', {'learning_rate': lr, 'beta1': beta1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "We recommend to use gpu to boost training. After a few epochs, we can see human-face-like images are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "\n",
    "real_label = mx.nd.ones((batch_size,), ctx=ctx)\n",
    "fake_label = mx.nd.zeros((batch_size,),ctx=ctx)\n",
    "\n",
    "def facc(label, pred):\n",
    "    pred = pred.ravel()\n",
    "    label = label.ravel()\n",
    "    return ((pred > 0.5) == label).mean()\n",
    "metric = mx.metric.CustomMetric(facc)\n",
    "\n",
    "stamp =  datetime.now().strftime('%Y_%m_%d-%H_%M')\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    btic = time.time()\n",
    "    train_data.reset()\n",
    "    iter = 0\n",
    "    for batch in train_data:\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        data = batch.data[0].as_in_context(ctx)\n",
    "        latent_z = mx.nd.random_normal(0, 1, shape=(batch_size, latent_z_size, 1, 1), ctx=ctx)\n",
    "\n",
    "        with autograd.record():\n",
    "            # train with real image\n",
    "            output = netD(data).reshape((-1, 1))\n",
    "            errD_real = loss(output, real_label)\n",
    "            metric.update([real_label,], [output,])\n",
    "\n",
    "            # train with fake image\n",
    "            fake = netG(latent_z)\n",
    "            output = netD(fake).reshape((-1, 1))\n",
    "            errD_fake = loss(output, fake_label)\n",
    "            errD = errD_real + errD_fake\n",
    "            errD.backward()\n",
    "            metric.update([fake_label,], [output,])\n",
    "\n",
    "        trainerD.step(batch.data[0].shape[0])\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        with autograd.record():\n",
    "            fake = netG(latent_z)\n",
    "            output = netD(fake).reshape((-1, 1))\n",
    "            errG = loss(output, real_label)\n",
    "            errG.backward()\n",
    "\n",
    "        trainerG.step(batch.data[0].shape[0])\n",
    "\n",
    "        # Print log infomation every ten batches\n",
    "        if iter % 10 == 0:\n",
    "            name, acc = metric.get()\n",
    "            logging.info('speed: {} samples/s'.format(batch_size / (time.time() - btic)))\n",
    "            logging.info('discriminator loss = %f, generator loss = %f, binary training acc = %f at iter %d epoch %d' \n",
    "                     %(nd.mean(errD).asscalar(), \n",
    "                       nd.mean(errG).asscalar(), acc, iter, epoch))\n",
    "        iter = iter + 1\n",
    "        btic = time.time()\n",
    "\n",
    "    name, acc = metric.get()\n",
    "    metric.reset()\n",
    "    logging.info('\\nbinary training acc at epoch %d: %s=%f' % (epoch, name, acc))\n",
    "    logging.info('time: %f' % (time.time() - tic))\n",
    "\n",
    "    # Visualize one generated image for each epoch\n",
    "    fake_img = fake[0]\n",
    "    visualize(fake_img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results\n",
    "Generate some face images with generator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_image = 8\n",
    "for i in range(num_image):\n",
    "    latent_z = mx.nd.random_normal(0, 1, shape=(1, latent_z_size, 1, 1), ctx=ctx)\n",
    "    img = netG(latent_z)\n",
    "    plt.subplot(2,4,i+1)\n",
    "    visualize(img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk in the latent space. We can see that small changes in the latent space result in smooth changes in generated images. This is a good sign that the model has learnt relevant and interesting representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_image = 12\n",
    "latent_z = mx.nd.random_normal(0, 1, shape=(1, latent_z_size, 1, 1), ctx=ctx)\n",
    "step = 0.05\n",
    "for i in range(num_image):\n",
    "    img = netG(latent_z)\n",
    "    plt.subplot(3,4,i+1)\n",
    "    visualize(img[0])\n",
    "    latent_z += 0.05\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
